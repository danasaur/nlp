{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jkchandalia/nlp/blob/main/NLP_intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MB2JOABMiM4Q"
      },
      "source": [
        "# **Intro to Practical Hands-on Deep Learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zJKw3PM8-vL"
      },
      "source": [
        "**Import** Libraries "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9vmG-hk894X"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rht5jZf89DGB"
      },
      "source": [
        "## Structuring Unstructured Data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to begin with some background and motivation for what we do in the later parts of the tutorial.  We will start by looking at two sentences that are similar:\n",
        "\n",
        "\n",
        "\n",
        "1.   The cat took a nap on the rug.\n",
        "2.   The feline slept in the sunshine. \n",
        "\n",
        "\n",
        "\n",
        "Do we feel like there’s a similar idea being presented in these two sentences? \n",
        "What about the below sentence?\n",
        "\n",
        "\n",
        "3.   The cat took a bite of the rug.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "54nPj9oICG1c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Is there a way to quantify our feelings about the differences/similarities between these three sentences? Let's try something simple and represent each sentence as an array:"
      ],
      "metadata": {
        "id": "bfFtyiBJCtGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s1 = ['The', 'cat', 'took', 'a', 'nap', 'on', 'the', 'rug']\n",
        "s2 = ['The', 'feline', 'slept', 'in', 'the', 'sunshine']\n",
        "s3 = ['The', 'cat', 'took', 'a', 'bite', 'of', 'the', 'rug']\n"
      ],
      "metadata": {
        "id": "YvNGp-m_Cz0W"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And let’s try to quantify the differences between the vectors by representing a word match as a 1 and a word mismatch as a 0. For instance, for the first two sentences we have:\n",
        "\n",
        "[1, 0, 0, 0, 0, 0, 0, 0]\n",
        "\n",
        "Because only ‘The’ is common between the sentences. \n",
        "\n",
        "For the first and third sentences, we have:\n",
        "\n",
        "[1, 1, 1, 1, 0, 0, 1, 1]\n"
      ],
      "metadata": {
        "id": "MBsbLw8XEPS-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because ‘The’, ‘cat’, ‘took’, ‘a’, ‘the’, and ‘rug’ are common words in the two sentences. If we simple add up all the numbers in each vector to get an idea of how similar the sentences are, we have:\n",
        "\n",
        "1 for similarity between sentences 1 and 2\n",
        "6 for similarity between sentences 1 and 3\n",
        "\n",
        "Using our approach, which sentences are more similar? Does this match our intuition for which sentences are most similar/dissimilar out of our examples? How are we handling sentences of different length?\n"
      ],
      "metadata": {
        "id": "0I7Uow_XEawV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To quantify differences between sentences, we need to represent them in a numerical way. However, we also need this numerical representation to reflect what the sentences actually mean, i.e., capture the semantic content of these sentences and words. How can we do that?\n"
      ],
      "metadata": {
        "id": "bJE8zONoEhOM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Large Language Models (LLM)"
      ],
      "metadata": {
        "id": "dGUHKiJpEqyu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Self-supervised learning"
      ],
      "metadata": {
        "id": "qFFkvoLQKXcU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AUXqyASPDvhm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformer Encoder"
      ],
      "metadata": {
        "id": "Hey5iWMwF5LA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Attention Mechanism"
      ],
      "metadata": {
        "id": "8ba7VbG5GSoW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Traditionally, modeling sequences has been challenging but the general idea is that we want to express the information contained in the sequence into a compressed form and use that compressed form to generate an output. The output could be a translation of the original sequence into a new language or a classification. Taking the example from above, this means the above sentences that are semantically similar will be mapped to something similar in the compressed form while dissimilar sentences will be further apart. What transformed (pun intended) this compression step is the concept of attention. \n",
        "\n",
        "I’m going to need to gloss over the technical details, but basically for each item in our sequence, we ask or query each item in our sequence to see how important or relevant it is for us. Of course this is done through matrix multiplications which we will not get into here. For this example sentence:\n",
        "\n",
        "“The cat purred in happiness”\n",
        "\n",
        "one could imagine that cat and purr attend to each other, likely because the english language reflects that cats purring is much more likely than say an elephant purring. After going through an attention layer, each item in the transformed sequence is actually a mixture of itself and all other items that contribute to the meaning of itself. By passing inputs through many such layers, we generate a representation of our original input that does capture the semantic meaning of our original input. \n"
      ],
      "metadata": {
        "id": "W0WOhKR4KHGX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transfer Learning"
      ],
      "metadata": {
        "id": "_rSXb_KXGZOA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Generation:\n",
        "Use chatgpt to create a poem that we will classify in the next section!"
      ],
      "metadata": {
        "id": "6aoDedveG5gd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://chat.openai.com/"
      ],
      "metadata": {
        "id": "Obx0QjBgByIP"
      }
    }
  ]
}